---
title: "ST 558: Project 1"
author: Kayla Kippes and Zack Rosen
date: 6/16/2025
format: pdf
editor: visual
---

For this project, our goal was to manipulate and process data sets that came in a certain form. To start this process, we completed each individual step on one data set. This allowed us to ensure the content of our functions would be working properly. Then we added each of those steps into their respective functions. After that, we created a wrapper function to pull everything into one place. From there we combined the necessary data sets and performed unique types of the plot function. The rest of this document will talk through each function and give examples of all of our functions coming together to be used on actual data.

## Function 1: Read and Convert Data

We first started by preprocessing the read data.  This involved selecting useful columns, namely, Area_name, STCOU and those that end with "D". The tidyverse package was extremely useful for data preprocessing techniques and manipulations such as these.  We then renamed the column for consistency, and converted the data from a wide to a long format. To do this, we transformed the columns ending in "D" into a single column named "survey_value" and mapped the corresponding original value to these observations by adding a new column.  This new column was named by the column_name variable, which was included in the function signature as an optional parameter with the default value of "enrollment".

```{r}
#| warning: false
#| message: false

library(tidyverse)

read_and_preprocess <- function(data, column_name = "enrollment") {
  # Step 1
  ## select / rename columns
  EDU01a <- data |>
    select(Area_name, STCOU, ends_with("D")) |>
    rename("area_name" = "Area_name")
  ## print out the first 5 rows
  print("Preprocessed:")
  print(head(EDU01a, 5))
  
  # Step 2
  # pivot cols 3-12 into long format
  long_tibble <- EDU01a |>
    pivot_longer(cols = 3:12, names_to = "survey_value", values_to = column_name)
  ## print out the first 5 rows
  print("Long format:")
  print(head(long_tibble, 5))
  
  ##return long data
  return(long_tibble)
}
```

## Function 2: Parsing the Data and Creating New Varaiables

In order to parse the data and create new variables, We figured "mutate" would have to be used. Since each year was embedded into the "survery_value" column and every value in that column was the same length, we were able to sub string the year out and make it a numeric. However, this only gave us two digits and we wanted four digit years. To solve for this, we added an "if" statement to add either 1900 or 2000 to the two digit year (this wouldn't have worked if the data includes years below 1925). Also, we had made a temporary column initially with the short year so we decided to select all other columns except for the one that wasn't needed.

```{r}
#| message: false

parse_new_variables <- function(long_tibble) {
  long_updated <- long_tibble |> 
  mutate(short_year = as.numeric(substr(survey_value, 8, 9)), 
         year = ifelse(short_year > 25, 1900 + short_year, 2000 + short_year),
         measurement = substr(survey_value, 1, 7)) |>
  select(-short_year)
  ## print out the first 5 rows
  print("Updated:")
  print(head(long_updated, 5))
  
  ## returns long updated
  return(long_updated)
}
```

## Function 3: County Level

Similar to the year scenario above, we had to use "substr" to create a state column for the county data. This was a bit trickier as the values in area_name were not all the same length. To solve for this, we need to grab the max number of characters in the string and pull the second to last and last one so we could get the two character state value.

```{r}
#| message: false

## add state column
add_state_col_county <- function(county_tibble) {
  county_tibble <- county_tibble |>
  mutate(state = substr(area_name, nchar(area_name) - 1, nchar(area_name)))
  ## return the tibble
  return(county_tibble)
}
```


## Function 4: Non-County Level

Similar to the above functions, we figured that "mutate" would be the best way to add a new division column. This new column's values were determined by a case_when statement that checked if the area_name of that observation was in a vector corresponding to one of the Census Bureau's designated divisions. After all of these divisions were checked, we added the value "ERROR" to the division column if none of the divisions were a match.

```{r}
#| message: false

add_division_col_state <- function(state_tibble) {
  # Step 6
  ## create division variable and set division by state name, else ERROR
  state_tibble <- state_tibble |>
    mutate(division = case_when(
      area_name %in% c("CONNECTICUT", "MAINE", 
                       "MASSACHUSETTS", "NEW HAMPSHIRE", 
                       "RHODE ISLAND", "VERMONT") ~ "New England",
      area_name %in% c("NEW JERSEY", "NEW YORK", 
                       "PENNSYLVANIA") ~ "Mid-Atlantic",
      area_name %in% c("ILLINOIS", "INDIANA", "MICHIGAN", "OHIO", 
                       "WISCONSIN") ~ "East North Central",
      area_name %in% c("IOWA", "KANSAS", "MINNESOTA", "MISSOURI", 
                       "NEBRASKA", "NORTH DAKOTA", 
                       "SOUTH DAKOTA") ~ "West North Central",
      area_name %in% c("DELAWARE", "DISTRICT OF COLUMBIA", "FLORIDA", 
                       "GEORGIA", "MARYLAND", "NORTH CAROLINA", 
                       "SOUTH CAROLINA", "VIRGINIA", 
                       "WEST VIRGINIA") ~ "South Atlantic",
      area_name %in% c("ALABAMA", "KENTUCKY", "MISSISSIPPI", 
                       "TENNESSEE") ~ "East South Central",
      area_name %in% c("ARKANSAS", "LOUISIANA", "OKLAHOMA", 
                       "TEXAS") ~ "West South Central",
      area_name %in% c("ARIZONA", "COLORADO", "IDAHO", "MONTANA", "NEVADA", 
                       "NEW MEXICO", "UTAH", "WYOMING") ~ "Mountain",
      area_name %in% c("ALASKA", "CALIFORNIA", "HAWAII", "OREGON", 
                       "WASHINGTON") ~ "Pacific",
      TRUE ~ "ERROR"))
  return(state_tibble)
}
```

## Function 5: Returning Two Final Tibbles

This function filters the long format data into two tibbles: a county-level tibble and a state-level tibble.  The county-level tibble corresponds to county entries, with area_name values identified by a comma and a two letter state abbreviation.  The state-level tibble was simply all of the other entries that were not in the county-level tibble. Lastly, a county class was added to the county-level tibble and a state class was added to the state-level tibble.

```{r}
#| message: false

create_datasets <- function(long_updated) {
  # Step 4
  ## get the county indices
  county_indices <- grep(pattern = ", \\w\\w", long_updated$area_name)
  ## create the non-county data
  state_tibble <- long_updated[-county_indices,]
  ## create the county data
  county_tibble <- long_updated[county_indices,]
  ## add a class to the county tibble
  class(county_tibble) <- c("county", class(county_tibble))
  ## add a class to the state tibble
  class(state_tibble) <- c("state", class(state_tibble))
  ## print out the first 10 rows
  print("State tibble:")
  print(head(state_tibble, 10))
  print("County tibble:")
  print(head(county_tibble, 10))
  
  final_county_tibble <- add_state_col_county(county_tibble)
  final_state_tibble <- add_division_col_state(state_tibble)
  return(list(county = final_county_tibble, state = final_state_tibble))
}
```

## Wrapper Function

The outline for this one was very helpful as it pointed us to the format. Besides the initial csv read, we don't define any variables for the other functions because we assume the output of the previous function will be used as input for the next function. This makes it easier as there are less things to input.

```{r}
#| message: false

my_wrapper <- function(url, default_var_name = "enrollment"){
  result <- read_csv(url) |>
    read_and_preprocess() |>
    parse_new_variables() |>
    create_datasets()
 ## return final result
  return(result)
 }
```

## Combine Function

Here we are doing a simple combination of all the specific county and state data.

```{r}
#| message: false

combine_results <- function(result1, result2) {
  list(county = dplyr::bind_rows(result1$county, result2$county),
       state = dplyr::bind_rows(result1$state, result2$state))
}
```

## Custom Plot Function

We created our own classes by writing custom plot functions, unique to our data.

### State

For plot state function, we had to filter out all observations that had a division value of "ERROR". We then had to figure out how to group by division across the year variable. This is easily done with a group_by statement that takes in division as the first argument and then year as the second. We then summarized by using the mean of the grouped var_name variable and, we decided that a line plot with many colored lines would be the best way to visualize this. Each line's color corresponds to a division.

```{r}
#| message: false

plot.state <- function(df, var_name = "enrollment") {
  df |>
    ## filter out ERROR entries and group by division across years
    filter(division != "ERROR") |>
    group_by(division, year) |>
    ## then find the mean of var_name (default is enrollment)
    summarize(mean_val = mean(get(var_name), na.rm = TRUE)) |>
    ## plot the statistic
    ggplot(aes(x = year, y = mean_val, color = division)) +
    geom_line() +
    labs(title = paste("Mean", var_name, "across years by division"),
         y = paste("Mean", var_name),
         x = "Year")
}
```

### County

To start this plot county function, a certain state had to be filtered. This helped narrow down the data set. From there we had to group by area name in order to get our mean statistics. The difficult part about arranging these statistics was that it was dependent on an inputted value so we had to imply if else logic. After that we only choose the n number of specified rows. That was now considered our sorted data but we didn't want to only use that data for the plot. Instead we had to go back to our original filtered data and filter it again to only include the area names in the top or bottom n records. To view this neatly, we decided a box plot would be the best visualization.

```{r}
#| message: false

plot.county <- function(county_tibble, var_name = "enrollment", state = "NC", 
                        direction = "top", n = 5) {
  ## filter for the selected state
  filtered_state <- county_tibble |>
    filter(state == state)
  
  ## find the mean by area_name and sort the data
  sorted_data <- filtered_state |>
    group_by(area_name) |>
    summarize(mean_val = mean(get(var_name), na.rm = TRUE)) |>
    arrange(if (direction == "top") {
      desc(mean_val)
    } else {
      mean_val
    }) |>
    slice_head(n = n)
  
  ## filter for state from above
  new_sorted_data <- filtered_state |>
    filter(area_name %in% sorted_data$area_name)
  
  ## plot the statistic
  ggplot(new_sorted_data, aes(x = area_name, y = get(var_name))) + 
    geom_boxplot() + 
    labs(title = paste(direction, n, "Counties in", state),
         y = var_name,
         x = "County") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
```


## Putting it All Together

Here we put it all together using two data sets and then using a different four data sets.

### Two Enrollment Datasets

The goal here was to process two different data sets and save the results to their own respective variables. After that, we combined those results so we are left with a list that contains a combined state data frame and a combined tibble data frame. From there we used our state plot function to give us mean enrollment by division over time. Then we use the county plot function to retrieve a certain number of box plots of the enrollment data for the top or bottom area names in a specified state.

```{r}
#| message: false

## using data processing on two enrollment datasets
result1 <- my_wrapper("data/EDU01a.csv")
result2 <- my_wrapper("data/EDU01b.csv")

## combining data sets
combined_results <- combine_results(result1, result2)

## use plot function on state
plot(combined_results$state)

## use plot on county data
## scenario one
plot(combined_results$county, state = "NC", direction="top", n = 20)
## scenario two
plot(combined_results$county, state = "SC", direction="bottom", n = 7)
## scenario three
plot(combined_results$county)
##scenario four
plot(combined_results$county, state = "PA", direction="top", n = 8)

```

### Four Additional Data Sets

The goal here was to process four additional data sets and save those into four respective variables. Then, two at a time, the results were combined into two new results called a_prime and b_prime. Lastly a_prime and b_prime were combined into one final result variable which contained all four additional data sets. Then we used the state plot function and the county plot function. The county plot function was called four times with four different combinations of arguments.

```{r}
#| message: false

## using data processing on four additional datasets
a <- my_wrapper("data/PST01a.csv")
b <- my_wrapper("data/PST01b.csv")
c <- my_wrapper("data/PST01c.csv")
d <- my_wrapper("data/PST01d.csv")

## combine four datasets into one
a_prime <- combine_results(a, b)
b_prime <- combine_results(c, d)
four_combined_results <-combine_results(a_prime, b_prime)

## use plot function on state
plot(four_combined_results$state)

## use plot on county data
## scenario one
plot(four_combined_results$county, state = "CA", direction="top", n = 15)
## scenario two
plot(four_combined_results$county, state = "TX", direction="top", n = 4)
## scenario three
plot(four_combined_results$county)
##scenario four
plot(four_combined_results$county, state = "NY", direction="top", n = 10)
```
